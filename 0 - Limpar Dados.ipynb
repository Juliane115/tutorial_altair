{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aquisição e Limpeza de dados\n",
    "\n",
    "Esse notebook documenta o processamento dos datasets baixados do INMET, com os agrupamentos necessários pra criar os arquivos `dados.csv`, `completo.csv` e `metadados.csv`.\n",
    "\n",
    "Não é necessário para o resto do curso.\n",
    "\n",
    "Baixe o arquivo do site [Dados históricos do INMET](https://portal.inmet.gov.br/dadoshistoricos), selecionando o ano de 2019 todo.\n",
    "\n",
    "Descompacte em uma pasta, seguindo a estrutura:\n",
    "``` bash\n",
    "- baixado\n",
    "--- extraído\n",
    "```\n",
    "\n",
    "Estamos prontos para ver os arquivos, mas mesmo sem abrir eles podemos ter alguma informação sobre esses dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos listar todos os arquivos e ver quantas cidades tem por estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INMET_CO_DF_A001_BRASILIA_01-01-2019_A_31-12-2019.CSV', 'INMET_CO_DF_A042_BRAZLANDIA_01-01-2019_A_31-12-2019.CSV', 'INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2019_A_31-12-2019.CSV', 'INMET_CO_DF_A046_GAMA (PONTE ALTA)_01-01-2019_A_31-12-2019.CSV']\n"
     ]
    }
   ],
   "source": [
    "prefixo = \"baixado/descompactado/\"\n",
    "nome_arquivos = os.listdir(prefixo)\n",
    "print(nome_arquivos[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['INMET', 'CO', 'DF', 'A001', 'BRASILIA', '01-01-2019', 'A', '31-12-2019.CSV'], ['INMET', 'CO', 'DF', 'A042', 'BRAZLANDIA', '01-01-2019', 'A', '31-12-2019.CSV']]\n",
      "['DF', 'DF', 'DF', 'DF', 'DF', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO']\n",
      "['AC', 'AL', 'AM', 'AP', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MG', 'MS', 'MT', 'PA', 'PB', 'PE', 'PI', 'PR', 'RJ', 'RN', 'RO', 'RR', 'RS', 'SC', 'SE', 'SP', 'TO']\n"
     ]
    }
   ],
   "source": [
    "siglas_estado = [nome.split(\"_\") for nome in nome_arquivos]\n",
    "print(siglas_estado[:2]) # tem mais informações que só as iniciais\n",
    "siglas_estado = [nome[2] for nome in siglas_estado]\n",
    "print(siglas_estado[:20]) # agora está certo\n",
    "siglas = list(set(siglas_estado))\n",
    "siglas.sort()\n",
    "print(siglas) # todos os estados estão presentes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estado</th>\n",
       "      <th>cidades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AC</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AM</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BA</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CE</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ES</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GO</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MA</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MG</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MS</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MT</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PA</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PB</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PE</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PI</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PR</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RJ</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RS</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SC</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SE</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SP</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TO</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estado  cidades\n",
       "0      AC        7\n",
       "1      AL        7\n",
       "2      AM       19\n",
       "3      AP        4\n",
       "4      BA       47\n",
       "5      CE       16\n",
       "6      DF        5\n",
       "7      ES       13\n",
       "8      GO       26\n",
       "9      MA       17\n",
       "10     MG       67\n",
       "11     MS       45\n",
       "12     MT       39\n",
       "13     PA       31\n",
       "14     PB        9\n",
       "15     PE       13\n",
       "16     PI       21\n",
       "17     PR       26\n",
       "18     RJ       26\n",
       "19     RN        9\n",
       "20     RO        4\n",
       "21     RR        1\n",
       "22     RS       44\n",
       "23     SC       24\n",
       "24     SE        7\n",
       "25     SP       42\n",
       "26     TO       20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_estado = []\n",
    "for s in siglas:\n",
    "    dados_estado.append({\"estado\":s, \"cidades\": siglas_estado.count(s)})\n",
    "dataframe = pd.DataFrame(dados_estado)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tabela não ajuda muito a ver a distribuição, é melhor com um gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-a429bd57651f4574b106badc69602b2e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a429bd57651f4574b106badc69602b2e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a429bd57651f4574b106badc69602b2e\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-0c34143bd7abda4691e046ee82d64572\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"type\": \"nominal\", \"field\": \"estado\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"cidades\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-0c34143bd7abda4691e046ee82d64572\": [{\"estado\": \"AC\", \"cidades\": 7}, {\"estado\": \"AL\", \"cidades\": 7}, {\"estado\": \"AM\", \"cidades\": 19}, {\"estado\": \"AP\", \"cidades\": 4}, {\"estado\": \"BA\", \"cidades\": 47}, {\"estado\": \"CE\", \"cidades\": 16}, {\"estado\": \"DF\", \"cidades\": 5}, {\"estado\": \"ES\", \"cidades\": 13}, {\"estado\": \"GO\", \"cidades\": 26}, {\"estado\": \"MA\", \"cidades\": 17}, {\"estado\": \"MG\", \"cidades\": 67}, {\"estado\": \"MS\", \"cidades\": 45}, {\"estado\": \"MT\", \"cidades\": 39}, {\"estado\": \"PA\", \"cidades\": 31}, {\"estado\": \"PB\", \"cidades\": 9}, {\"estado\": \"PE\", \"cidades\": 13}, {\"estado\": \"PI\", \"cidades\": 21}, {\"estado\": \"PR\", \"cidades\": 26}, {\"estado\": \"RJ\", \"cidades\": 26}, {\"estado\": \"RN\", \"cidades\": 9}, {\"estado\": \"RO\", \"cidades\": 4}, {\"estado\": \"RR\", \"cidades\": 1}, {\"estado\": \"RS\", \"cidades\": 44}, {\"estado\": \"SC\", \"cidades\": 24}, {\"estado\": \"SE\", \"cidades\": 7}, {\"estado\": \"SP\", \"cidades\": 42}, {\"estado\": \"TO\", \"cidades\": 20}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(dataframe).mark_bar().encode(\n",
    "    x=\"estado\",\n",
    "    y=\"cidades\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dá pra ver melhor a disparidade, mas no nosso caso queremos só o Pará.  \n",
    "Vamos ler um arquivo com a sigla `PA` e ver como está o formato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['REGI?O:;CO\\n',\n",
      " 'UF:;DF\\n',\n",
      " 'ESTAC?O:;BRASILIA\\n',\n",
      " 'CODIGO (WMO):;A001\\n',\n",
      " 'LATITUDE:;-15,789343\\n',\n",
      " 'LONGITUDE:;-47,925756\\n',\n",
      " 'ALTITUDE:;1160,96\\n',\n",
      " 'DATA DE FUNDAC?O:;07/05/00\\n',\n",
      " 'Data;Hora UTC;PRECIPITAÇÃO TOTAL, HORÁRIO (mm);PRESSAO ATMOSFERICA AO NIVEL '\n",
      " 'DA ESTACAO, HORARIA (mB);PRESSÃO ATMOSFERICA MAX.NA HORA ANT. (AUT) '\n",
      " '(mB);PRESSÃO ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB);RADIACAO GLOBAL '\n",
      " '(W/m²);TEMPERATURA DO AR - BULBO SECO, HORARIA (°C);TEMPERATURA DO PONTO DE '\n",
      " 'ORVALHO (°C);TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C);TEMPERATURA MÍNIMA '\n",
      " 'NA HORA ANT. (AUT) (°C);TEMPERATURA ORVALHO MAX. NA HORA ANT. (AUT) '\n",
      " '(°C);TEMPERATURA ORVALHO MIN. NA HORA ANT. (AUT) (°C);UMIDADE REL. MAX. NA '\n",
      " 'HORA ANT. (AUT) (%);UMIDADE REL. MIN. NA HORA ANT. (AUT) (%);UMIDADE '\n",
      " 'RELATIVA DO AR, HORARIA (%);VENTO, DIREÇÃO HORARIA (gr) (° (gr));VENTO, '\n",
      " 'RAJADA MAXIMA (m/s);VENTO, VELOCIDADE HORARIA (m/s);\\n',\n",
      " '2019/01/01;0000 '\n",
      " 'UTC;1;887;887;886,6;;18,5;17;18,7;18,4;17,3;16,9;92;91;91;330;5,3;2;\\n',\n",
      " '2019/01/01;0100 '\n",
      " 'UTC;0;888,1;888,1;887;;18,4;17,1;18,5;18,3;17,2;16,9;92;91;92;326;4,3;,8;\\n',\n",
      " '2019/01/01;0200 '\n",
      " 'UTC;0;888,2;888,3;888,1;;18,5;17,3;18,6;18,3;17,4;17,1;93;92;93;340;2,2;1,3;\\n',\n",
      " '2019/01/01;0300 '\n",
      " 'UTC;,4;887,6;888,2;887,6;;18,4;17,1;18,7;18,4;17,5;17,1;93;92;92;351;2,2;1,4;\\n',\n",
      " '2019/01/01;0400 '\n",
      " 'UTC;0;887;887,6;887;;17,9;16,7;18,4;17,9;17,2;16,7;93;92;93;343;2;1,3;\\n',\n",
      " '2019/01/01;0500 '\n",
      " 'UTC;0;886,8;887;886,6;;17,9;16,7;18,3;17,9;17,3;16,7;94;93;93;337;2;,7;\\n',\n",
      " '2019/01/01;0600 '\n",
      " 'UTC;0;886,8;886,8;886,7;;18,2;17,2;18,3;17,8;17,3;16,7;94;93;94;81;1,7;,3;\\n',\n",
      " '2019/01/01;0700 '\n",
      " 'UTC;0;886,9;887;886,7;;18,2;16,9;18,3;18;17,2;16,9;94;93;93;69;2,2;,6;\\n',\n",
      " '2019/01/01;0800 '\n",
      " 'UTC;0;887,2;887,3;886,9;;18,4;16,7;18,5;18,1;16,9;16,7;93;90;90;48;2,1;1,1;\\n',\n",
      " '2019/01/01;0900 '\n",
      " 'UTC;0;887,7;887,7;887,2;;18;16,7;18,4;18;16,9;16,6;92;90;92;278;2,5;,9;\\n',\n",
      " '2019/01/01;1000 '\n",
      " 'UTC;0;888,5;888,6;887,7;36,9;18,7;17,6;18,7;18;17,6;16,8;93;92;93;10;1,1;,3;\\n']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "with open(prefixo + nome_arquivos[0], \"r\") as arquivo:\n",
    "    pprint(arquivo.readlines()[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tem muita informação nas primeiras linhas do que a gente precisa, então vamos dividir: um arquivo de metadados e um arquivo com a informação dos sensores. Vamos começar adicionando os cabeçalhos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGIÃO,UF,ESTAÇÃO,CODIGO (WMO),LATITUDE,LONGITUDE,ALTITUDE,DATA DE FUNDAÇÃO\n",
      "\n",
      "Cidade,Data,Hora UTC,PRECIPITAÇÃO TOTAL | HORÁRIO (mm),PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO | HORARIA (mB),PRESSÃO ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB),PRESSÃO ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB),RADIACAO GLOBAL (W/m²),TEMPERATURA DO AR - BULBO SECO | HORARIA (°C),TEMPERATURA DO PONTO DE ORVALHO (°C),TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C),TEMPERATURA MÍNIMA NA HORA ANT. (AUT) (°C),TEMPERATURA ORVALHO MAX. NA HORA ANT. (AUT) (°C),TEMPERATURA ORVALHO MIN. NA HORA ANT. (AUT) (°C),UMIDADE REL. MAX. NA HORA ANT. (AUT) (%),UMIDADE REL. MIN. NA HORA ANT. (AUT) (%),UMIDADE RELATIVA DO AR | HORARIA (%),VENTO | DIREÇÃO HORARIA (gr) (° (gr)),VENTO | RAJADA MAXIMA (m/s),VENTO | VELOCIDADE HORARIA (m/s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dados = \"Cidade,\"\n",
    "metadados = \"\"\n",
    "\n",
    "with open(prefixo + nome_arquivos[0], \"r\", encoding=\"latin-1\") as arquivo:\n",
    "    linhas = arquivo.readlines()\n",
    "    dados += linhas[8][:-2].replace(\",\",\" |\").replace(\";\",\",\") + \"\\n\"\n",
    "    metadados = \",\".join([linha.split(\":;\")[0].replace(\"?\",\"Ã\").replace(\"CÃ\",\"ÇÃ\") for linha in linhas[:8]]) + \"\\n\"\n",
    "    print(metadados)\n",
    "    print(dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O cabeçalho dos dados ficou com muita informação extra, e um formato não tão agradável. Trocar o nome das colunas é uma função comum em vários processos de visualização, e será feito manualmente agora. Mas vamos salvar uma estrutura de chave valor, já que em vários títulos também tem informação sobre as medidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cidade': 'Cidade', 'Data': 'Data', 'Hora': 'Hora UTC', 'Precipitação': 'PRECIPITAÇÃO TOTAL | HORÁRIO (mm)', 'Pressão Atmosférica ao nível da estação': 'PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO | HORARIA (mB)', 'Pressão Atmosférica máxima': 'PRESSÃO ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB)', 'Pressão Atmosférica mínima': 'PRESSÃO ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB)', 'Radiação Global': 'RADIACAO GLOBAL (W/m²)', 'Temperatura do ar - bulbo seco': 'TEMPERATURA DO AR - BULBO SECO | HORARIA (°C)', 'Temperatura do ponto de orvalho': 'TEMPERATURA DO PONTO DE ORVALHO (°C)', 'Temperatura máxima': 'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)', 'Temperatura mínima': 'TEMPERATURA MÍNIMA NA HORA ANT. (AUT) (°C)', 'Temperatura orvalho máxima': 'TEMPERATURA ORVALHO MAX. NA HORA ANT. (AUT) (°C)', ' Temperatura orvalho mínima': 'TEMPERATURA ORVALHO MIN. NA HORA ANT. (AUT) (°C)', 'Umidade Relativa máxima': 'UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)', 'Umidade Relativa mínima': 'UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)', 'Umidade Relativa do Ar': 'UMIDADE RELATIVA DO AR | HORARIA (%)', 'Direção Horária do Vento': 'VENTO | DIREÇÃO HORARIA (gr) (° (gr))', 'Rajada Máxima de Vento': 'VENTO | RAJADA MAXIMA (m/s)', 'Velocidade Horária do Vento': 'VENTO | VELOCIDADE HORARIA (m/s)\\n'}\n"
     ]
    }
   ],
   "source": [
    "dados1 = \"Cidade,Data,Hora,Precipitação,Pressão Atmosférica ao nível da estação,\\\n",
    "Pressão Atmosférica máxima,Pressão Atmosférica mínima,Radiação Global,Temperatura do ar - bulbo seco,Temperatura do ponto de orvalho,\\\n",
    "Temperatura máxima,Temperatura mínima,Temperatura orvalho máxima, Temperatura orvalho mínima,\\\n",
    "Umidade Relativa máxima,Umidade Relativa mínima,Umidade Relativa do Ar,Direção Horária do Vento,Rajada Máxima de Vento,Velocidade Horária do Vento\"\n",
    "\n",
    "cabecalho = {}\n",
    "for d,d1 in zip(dados.split(\",\"),dados1.split(\",\")):\n",
    "    cabecalho[d1] = d\n",
    "\n",
    "print(cabecalho)\n",
    "import json\n",
    "\n",
    "with open(\"cabecalho.json\", \"w+\", encoding=\"utf-8\") as arquivo:\n",
    "    arquivo.write(json.dumps(cabecalho))\n",
    "\n",
    "dados = dados1 + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos adicionar os dados e salvar os arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_metadados(linhas):\n",
    "    return \",\".join([linha.split(\":;\")[1].replace(\"\\n\",\"\").replace(\",\",\".\") for linha in linhas[:8]]) + \"\\n\"\n",
    "\n",
    "for caminho, sigla in zip([prefixo + n for n in nome_arquivos], siglas_estado):\n",
    "    if sigla == \"PA\":\n",
    "        with open(caminho, \"r\", encoding=\"latin-1\") as arquivo:\n",
    "            linhas = arquivo.readlines()\n",
    "            metadados += extrair_metadados(linhas)\n",
    "            linhas_dados = [caminho.split(\"_\")[4] + \",\" + linha.replace(\",\",\".\").replace(\";\",\",\")[:-2] + \"\\n\" for linha in linhas[9:]]\n",
    "            dados += \"\".join(linhas_dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos salvar os dados completos e metadados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"completo.csv\", \"w+\", encoding=\"utf-8\") as arquivo:\n",
    "    arquivo.write(dados)\n",
    "\n",
    "with open(\"metadados.csv\", \"w+\", encoding=\"utf-8\") as arquivo:\n",
    "    arquivo.write(metadados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim vamos agrupar pela média de medições pelo dia para criar um arquivo mais leve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('completo.csv')\n",
    "df[\"Data\"] = pd.to_datetime(df[\"Data\"], infer_datetime_format=True)  \n",
    "df_leve = df.groupby([\"Cidade\",pd.Grouper(key='Data', freq='W')]).mean()\n",
    "df_leve.to_csv(\"dados.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tudo pronto! Só seguir para a primeira aula agora."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
