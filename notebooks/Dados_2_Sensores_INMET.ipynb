{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aquisição e Limpeza de dados\n",
    "\n",
    "Esse notebook documenta o processamento dos datasets baixados do INMET, com os agrupamentos necessários pra criar os arquivos `dados.csv`, `completo.csv` e `metadados.csv`.\n",
    "\n",
    "Baixe o arquivo do site [Dados históricos do INMET](https://portal.inmet.gov.br/dadoshistoricos), selecionando o ano de 2019 todo.\n",
    "\n",
    "Descompacte em uma pasta, seguindo a estrutura:\n",
    "``` bash\n",
    "- baixado\n",
    "--- descompactado\n",
    "```\n",
    "\n",
    "Estamos prontos para ver os arquivos, mas mesmo sem abrir eles podemos ter alguma informação sobre esses dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos listar todos os arquivos e ver quantas cidades tem por estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import json\n",
    "from io import StringIO\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INMET_CO_DF_A001_BRASILIA_01-01-2019_A_31-12-2019.CSV', 'INMET_CO_DF_A042_BRAZLANDIA_01-01-2019_A_31-12-2019.CSV', 'INMET_CO_DF_A045_AGUAS EMENDADAS_01-01-2019_A_31-12-2019.CSV', 'INMET_CO_DF_A046_GAMA (PONTE ALTA)_01-01-2019_A_31-12-2019.CSV']\n"
     ]
    }
   ],
   "source": [
    "prefixo = \"../baixado/descompactado/\"\n",
    "nome_arquivos = os.listdir(prefixo)\n",
    "print(nome_arquivos[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['INMET', 'CO', 'DF', 'A001', 'BRASILIA', '01-01-2019', 'A', '31-12-2019.CSV'], ['INMET', 'CO', 'DF', 'A042', 'BRAZLANDIA', '01-01-2019', 'A', '31-12-2019.CSV']]\n",
      "['DF', 'DF', 'DF', 'DF', 'DF', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO', 'GO']\n",
      "['AC', 'AL', 'AM', 'AP', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MG', 'MS', 'MT', 'PA', 'PB', 'PE', 'PI', 'PR', 'RJ', 'RN', 'RO', 'RR', 'RS', 'SC', 'SE', 'SP', 'TO']\n"
     ]
    }
   ],
   "source": [
    "siglas_estado = [nome.split(\"_\") for nome in nome_arquivos]\n",
    "print(siglas_estado[:2]) # tem mais informações que só as iniciais\n",
    "siglas_estado = [nome[2] for nome in siglas_estado]\n",
    "print(siglas_estado[:20]) # agora está certo\n",
    "siglas = list(set(siglas_estado))\n",
    "siglas.sort()\n",
    "print(siglas) # todos os estados estão presentes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estado</th>\n",
       "      <th>cidades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AC</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AM</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BA</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CE</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ES</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GO</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MA</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MG</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MS</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MT</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PA</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PB</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PE</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PI</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PR</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RJ</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RS</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SC</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SE</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SP</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TO</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estado  cidades\n",
       "0      AC        7\n",
       "1      AL        7\n",
       "2      AM       19\n",
       "3      AP        4\n",
       "4      BA       47\n",
       "5      CE       16\n",
       "6      DF        5\n",
       "7      ES       13\n",
       "8      GO       26\n",
       "9      MA       17\n",
       "10     MG       67\n",
       "11     MS       45\n",
       "12     MT       39\n",
       "13     PA       31\n",
       "14     PB        9\n",
       "15     PE       13\n",
       "16     PI       21\n",
       "17     PR       26\n",
       "18     RJ       26\n",
       "19     RN        9\n",
       "20     RO        4\n",
       "21     RR        1\n",
       "22     RS       44\n",
       "23     SC       24\n",
       "24     SE        7\n",
       "25     SP       42\n",
       "26     TO       20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_estado = []\n",
    "for s in siglas:\n",
    "    dados_estado.append({\"estado\":s, \"cidades\": siglas_estado.count(s)})\n",
    "dataframe = pd.DataFrame(dados_estado)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tabela não ajuda muito a ver a distribuição, é melhor com um gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-19a75b9c3c7a492a9b0237a016e190e2\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-19a75b9c3c7a492a9b0237a016e190e2\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-19a75b9c3c7a492a9b0237a016e190e2\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-0c34143bd7abda4691e046ee82d64572\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"type\": \"nominal\", \"field\": \"estado\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"cidades\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-0c34143bd7abda4691e046ee82d64572\": [{\"estado\": \"AC\", \"cidades\": 7}, {\"estado\": \"AL\", \"cidades\": 7}, {\"estado\": \"AM\", \"cidades\": 19}, {\"estado\": \"AP\", \"cidades\": 4}, {\"estado\": \"BA\", \"cidades\": 47}, {\"estado\": \"CE\", \"cidades\": 16}, {\"estado\": \"DF\", \"cidades\": 5}, {\"estado\": \"ES\", \"cidades\": 13}, {\"estado\": \"GO\", \"cidades\": 26}, {\"estado\": \"MA\", \"cidades\": 17}, {\"estado\": \"MG\", \"cidades\": 67}, {\"estado\": \"MS\", \"cidades\": 45}, {\"estado\": \"MT\", \"cidades\": 39}, {\"estado\": \"PA\", \"cidades\": 31}, {\"estado\": \"PB\", \"cidades\": 9}, {\"estado\": \"PE\", \"cidades\": 13}, {\"estado\": \"PI\", \"cidades\": 21}, {\"estado\": \"PR\", \"cidades\": 26}, {\"estado\": \"RJ\", \"cidades\": 26}, {\"estado\": \"RN\", \"cidades\": 9}, {\"estado\": \"RO\", \"cidades\": 4}, {\"estado\": \"RR\", \"cidades\": 1}, {\"estado\": \"RS\", \"cidades\": 44}, {\"estado\": \"SC\", \"cidades\": 24}, {\"estado\": \"SE\", \"cidades\": 7}, {\"estado\": \"SP\", \"cidades\": 42}, {\"estado\": \"TO\", \"cidades\": 20}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(dataframe).mark_bar().encode(\n",
    "    x=\"estado\",\n",
    "    y=\"cidades\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dá pra ver melhor a disparidade, mas no nosso caso queremos só o Pará.  \n",
    "Vamos ler um arquivo com a sigla `PA` e ver como está o formato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['REGI?O:;CO\\n',\n",
      " 'UF:;DF\\n',\n",
      " 'ESTAC?O:;BRASILIA\\n',\n",
      " 'CODIGO (WMO):;A001\\n',\n",
      " 'LATITUDE:;-15,789343\\n',\n",
      " 'LONGITUDE:;-47,925756\\n',\n",
      " 'ALTITUDE:;1160,96\\n',\n",
      " 'DATA DE FUNDAC?O:;07/05/00\\n',\n",
      " 'Data;Hora UTC;PRECIPITAÇÃO TOTAL, HORÁRIO (mm);PRESSAO ATMOSFERICA AO NIVEL '\n",
      " 'DA ESTACAO, HORARIA (mB);PRESSÃO ATMOSFERICA MAX.NA HORA ANT. (AUT) '\n",
      " '(mB);PRESSÃO ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB);RADIACAO GLOBAL '\n",
      " '(W/m²);TEMPERATURA DO AR - BULBO SECO, HORARIA (°C);TEMPERATURA DO PONTO DE '\n",
      " 'ORVALHO (°C);TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C);TEMPERATURA MÍNIMA '\n",
      " 'NA HORA ANT. (AUT) (°C);TEMPERATURA ORVALHO MAX. NA HORA ANT. (AUT) '\n",
      " '(°C);TEMPERATURA ORVALHO MIN. NA HORA ANT. (AUT) (°C);UMIDADE REL. MAX. NA '\n",
      " 'HORA ANT. (AUT) (%);UMIDADE REL. MIN. NA HORA ANT. (AUT) (%);UMIDADE '\n",
      " 'RELATIVA DO AR, HORARIA (%);VENTO, DIREÇÃO HORARIA (gr) (° (gr));VENTO, '\n",
      " 'RAJADA MAXIMA (m/s);VENTO, VELOCIDADE HORARIA (m/s);\\n',\n",
      " '2019/01/01;0000 '\n",
      " 'UTC;1;887;887;886,6;;18,5;17;18,7;18,4;17,3;16,9;92;91;91;330;5,3;2;\\n',\n",
      " '2019/01/01;0100 '\n",
      " 'UTC;0;888,1;888,1;887;;18,4;17,1;18,5;18,3;17,2;16,9;92;91;92;326;4,3;,8;\\n',\n",
      " '2019/01/01;0200 '\n",
      " 'UTC;0;888,2;888,3;888,1;;18,5;17,3;18,6;18,3;17,4;17,1;93;92;93;340;2,2;1,3;\\n',\n",
      " '2019/01/01;0300 '\n",
      " 'UTC;,4;887,6;888,2;887,6;;18,4;17,1;18,7;18,4;17,5;17,1;93;92;92;351;2,2;1,4;\\n',\n",
      " '2019/01/01;0400 '\n",
      " 'UTC;0;887;887,6;887;;17,9;16,7;18,4;17,9;17,2;16,7;93;92;93;343;2;1,3;\\n',\n",
      " '2019/01/01;0500 '\n",
      " 'UTC;0;886,8;887;886,6;;17,9;16,7;18,3;17,9;17,3;16,7;94;93;93;337;2;,7;\\n',\n",
      " '2019/01/01;0600 '\n",
      " 'UTC;0;886,8;886,8;886,7;;18,2;17,2;18,3;17,8;17,3;16,7;94;93;94;81;1,7;,3;\\n',\n",
      " '2019/01/01;0700 '\n",
      " 'UTC;0;886,9;887;886,7;;18,2;16,9;18,3;18;17,2;16,9;94;93;93;69;2,2;,6;\\n',\n",
      " '2019/01/01;0800 '\n",
      " 'UTC;0;887,2;887,3;886,9;;18,4;16,7;18,5;18,1;16,9;16,7;93;90;90;48;2,1;1,1;\\n',\n",
      " '2019/01/01;0900 '\n",
      " 'UTC;0;887,7;887,7;887,2;;18;16,7;18,4;18;16,9;16,6;92;90;92;278;2,5;,9;\\n',\n",
      " '2019/01/01;1000 '\n",
      " 'UTC;0;888,5;888,6;887,7;36,9;18,7;17,6;18,7;18;17,6;16,8;93;92;93;10;1,1;,3;\\n']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "with open(prefixo + nome_arquivos[0], \"r\") as arquivo:\n",
    "    pprint(arquivo.readlines()[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tem muita informação nas primeiras linhas do que a gente precisa, então vamos dividir: um arquivo de metadados e um arquivo com a informação dos sensores. Vamos começar adicionando os cabeçalhos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGIÃO,UF,ESTAÇÃO,CODIGO (WMO),LATITUDE,LONGITUDE,ALTITUDE,DATA DE FUNDAÇÃO\n",
      "\n",
      "Cidade,Data,Hora UTC,PRECIPITAÇÃO TOTAL | HORÁRIO (mm),PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO | HORARIA (mB),PRESSÃO ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB),PRESSÃO ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB),RADIACAO GLOBAL (W/m²),TEMPERATURA DO AR - BULBO SECO | HORARIA (°C),TEMPERATURA DO PONTO DE ORVALHO (°C),TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C),TEMPERATURA MÍNIMA NA HORA ANT. (AUT) (°C),TEMPERATURA ORVALHO MAX. NA HORA ANT. (AUT) (°C),TEMPERATURA ORVALHO MIN. NA HORA ANT. (AUT) (°C),UMIDADE REL. MAX. NA HORA ANT. (AUT) (%),UMIDADE REL. MIN. NA HORA ANT. (AUT) (%),UMIDADE RELATIVA DO AR | HORARIA (%),VENTO | DIREÇÃO HORARIA (gr) (° (gr)),VENTO | RAJADA MAXIMA (m/s),VENTO | VELOCIDADE HORARIA (m/s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dados = \"Cidade,\"\n",
    "metadados = \"\"\n",
    "\n",
    "with open(prefixo + nome_arquivos[0], \"r\", encoding=\"latin-1\") as arquivo:\n",
    "    linhas = arquivo.readlines()\n",
    "    dados += linhas[8][:-2].replace(\",\",\" |\").replace(\";\",\",\") + \"\\n\"\n",
    "    metadados = \",\".join([linha.split(\":;\")[0].replace(\"?\",\"Ã\").replace(\"CÃ\",\"ÇÃ\") for linha in linhas[:8]]) + \"\\n\"\n",
    "    print(metadados)\n",
    "    print(dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O cabeçalho dos dados ficou com muita informação extra, e um formato não tão agradável. Trocar o nome das colunas é uma função comum em vários processos de visualização, e será feito manualmente agora. Mas vamos salvar uma estrutura de chave valor, já que em vários títulos também tem informação sobre as medidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cidade': 'Cidade', 'Data': 'Data', 'Hora': 'Hora UTC', 'Precipitação': 'PRECIPITAÇÃO TOTAL | HORÁRIO (mm)', 'Pressão Atmosférica ao nível da estação': 'PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO | HORARIA (mB)', 'Pressão Atmosférica máxima': 'PRESSÃO ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB)', 'Pressão Atmosférica mínima': 'PRESSÃO ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB)', 'Radiação Global': 'RADIACAO GLOBAL (W/m²)', 'Temperatura do ar - bulbo seco': 'TEMPERATURA DO AR - BULBO SECO | HORARIA (°C)', 'Temperatura do ponto de orvalho': 'TEMPERATURA DO PONTO DE ORVALHO (°C)', 'Temperatura máxima': 'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)', 'Temperatura mínima': 'TEMPERATURA MÍNIMA NA HORA ANT. (AUT) (°C)', 'Temperatura orvalho máxima': 'TEMPERATURA ORVALHO MAX. NA HORA ANT. (AUT) (°C)', 'Temperatura orvalho mínima': 'TEMPERATURA ORVALHO MIN. NA HORA ANT. (AUT) (°C)', 'Umidade Relativa máxima': 'UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)', 'Umidade Relativa mínima': 'UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)', 'Umidade Relativa do Ar': 'UMIDADE RELATIVA DO AR | HORARIA (%)', 'Direção Horária do Vento': 'VENTO | DIREÇÃO HORARIA (gr) (° (gr))', 'Rajada Máxima de Vento': 'VENTO | RAJADA MAXIMA (m/s)', 'Velocidade Horária do Vento': 'VENTO | VELOCIDADE HORARIA (m/s)\\n'}\n"
     ]
    }
   ],
   "source": [
    "dados1 = \"Cidade,Data,Hora,Precipitação,Pressão Atmosférica ao nível da estação,\\\n",
    "Pressão Atmosférica máxima,Pressão Atmosférica mínima,Radiação Global,Temperatura do ar - bulbo seco,Temperatura do ponto de orvalho,\\\n",
    "Temperatura máxima,Temperatura mínima,Temperatura orvalho máxima,Temperatura orvalho mínima,\\\n",
    "Umidade Relativa máxima,Umidade Relativa mínima,Umidade Relativa do Ar,Direção Horária do Vento,Rajada Máxima de Vento,Velocidade Horária do Vento\"\n",
    "\n",
    "cabecalho = {}\n",
    "for d,d1 in zip(dados.split(\",\"), dados1.split(\",\")):\n",
    "    cabecalho[d1] = d\n",
    "\n",
    "print(cabecalho)\n",
    "\n",
    "with open(\"../datasets/cabecalho.json\", \"w+\", encoding=\"utf-8\") as arquivo:\n",
    "    arquivo.write(json.dumps(cabecalho))\n",
    "\n",
    "dados = dados1 + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos adicionar os dados em dois arquivos, dos sensores e dos metadados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_metadados(linhas):\n",
    "    return \",\".join([linha.split(\":;\")[1].replace(\"\\n\",\"\").replace(\",\",\".\") for linha in linhas[:8]]) + \"\\n\"\n",
    "\n",
    "for caminho, sigla in zip([prefixo + n for n in nome_arquivos], siglas_estado):\n",
    "    if sigla == \"PA\":\n",
    "        with open(caminho, \"r\", encoding=\"latin-1\") as arquivo:\n",
    "            linhas = arquivo.readlines()\n",
    "            metadados += extrair_metadados(linhas)\n",
    "            linhas_dados = [caminho.split(\"_\")[4] + \",\" + linha.replace(\",\",\".\").replace(\";\",\",\")[:-2] + \"\\n\" for linha in linhas[9:]]\n",
    "            dados += \"\".join(linhas_dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nome das cidades não está condizente com o que vamos usar nos mapas, então vamos trocar pelos nomes no arquivo que será utilizado nos mapas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['REGIÃO', 'UF', 'ESTAÇÃO', 'CODIGO (WMO)', 'LATITUDE', 'LONGITUDE',\n",
      "       'ALTITUDE', 'DATA DE FUNDAÇÃO'],\n",
      "      dtype='object')\n",
      "['Abaetetuba', 'Abel Figueiredo', 'Acará', 'Afuá', 'Água Azul do Norte', 'Alenquer', 'Almeirim', 'Altamira', 'Anajás', 'Ananindeua', 'Anapu', 'Augusto Corrêa', 'Aurora do Pará', 'Aveiro', 'Bagre', 'Baião', 'Bannach', 'Barcarena', 'Belém', 'Belterra', 'Benevides', 'Bom Jesus do Tocantins', 'Bonito', 'Bragança', 'Brasil Novo', 'Brejo Grande do Araguaia', 'Breu Branco', 'Breves', 'Bujaru', 'Cachoeira do Piriá', 'Cachoeira do Arari', 'Cametá', 'Canaã dos Carajás', 'Capanema', 'Capitão Poço', 'Castanhal', 'Chaves', 'Colares', 'Conceição do Araguaia', 'Concórdia do Pará', 'Cumaru do Norte', 'Curionópolis', 'Curralinho', 'Curuá', 'Curuçá', 'Dom Eliseu', 'Eldorado dos Carajás', 'Faro', 'Floresta do Araguaia', 'Garrafão do Norte', 'Goianésia do Pará', 'Gurupá', 'Igarapé-Açu', 'Igarapé-Miri', 'Inhangapi', 'Ipixuna do Pará', 'Irituia', 'Itaituba', 'Itupiranga', 'Jacareacanga', 'Jacundá', 'Juruti', 'Limoeiro do Ajuru', 'Mãe do Rio', 'Magalhães Barata', 'Marabá', 'Maracanã', 'Marapanim', 'Marituba', 'Medicilândia', 'Melgaço', 'Mocajuba', 'Moju', 'Monte Alegre', 'Muaná', 'Nova Esperança do Piriá', 'Nova Ipixuna', 'Nova Timboteua', 'Novo Progresso', 'Novo Repartimento', 'Óbidos', 'Oeiras do Pará', 'Oriximiná', 'Ourém', 'Ourilândia do Norte', 'Pacajá', 'Palestina do Pará', 'Paragominas', 'Parauapebas', \"Pau D'Arco\", 'Peixe-Boi', 'Piçarra', 'Placas', 'Ponta de Pedras', 'Portel', 'Porto de Moz', 'Prainha', 'Primavera', 'Quatipuru', 'Redenção', 'Rio Maria', 'Rondon do Pará', 'Rurópolis', 'Salinópolis', 'Salvaterra', 'Santa Bárbara do Pará', 'Santa Cruz do Arari', 'Santa Isabel do Pará', 'Santa Luzia do Pará', 'Santa Maria das Barreiras', 'Santa Maria do Pará', 'Santana do Araguaia', 'Santarém', 'Santarém Novo', 'Santo Antônio do Tauá', 'São Caetano de Odivelas', 'São Domingos do Araguaia', 'São Domingos do Capim', 'São Félix do Xingu', 'São Francisco do Pará', 'São Geraldo do Araguaia', 'São João da Ponta', 'São João de Pirabas', 'São João do Araguaia', 'São Miguel do Guamá', 'São Sebastião da Boa Vista', 'Sapucaia', 'Senador José Porfírio', 'Soure', 'Tailândia', 'Terra Alta', 'Terra Santa', 'Tomé-Açu', 'Tracuateua', 'Trairão', 'Tucumã', 'Tucuruí', 'Ulianópolis', 'Uruará', 'Vigia', 'Viseu', 'Vitória do Xingu', 'Xinguara']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-b5ec39e11bd6>:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Cidade\"][indexes_cidade] = cidade\n",
      "<ipython-input-10-b5ec39e11bd6>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta[\"ESTAÇÃO\"][indexes_df_meta] = cidade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Belém' 'Castanhal' 'Medicilândia' 'Pacajá' 'Placas' 'Paragominas'\n",
      " 'TOME ACU' 'Rondon do Pará' 'Salinópolis' 'São Félix do Xingu' 'Bragança'\n",
      " 'Soure' 'Breves' 'Tucuruí' 'SERRA DOS CARAJAS' 'Itaituba' 'Óbidos'\n",
      " 'Santana do Araguaia' 'Tucumã' 'Novo Repartimento' 'Cametá'\n",
      " 'Monte Alegre' 'Marabá' 'Conceição do Araguaia' 'MINA DO PALITO'\n",
      " 'Xinguara' 'Capitão Poço' 'Santarém' 'Dom Eliseu' 'Altamira' 'Redenção']\n",
      "['Belém' 'Castanhal' 'Medicilândia' 'Pacajá' 'Placas' 'Paragominas'\n",
      " 'TOME ACU' 'Rondon do Pará' 'Salinópolis' 'São Félix do Xingu' 'Bragança'\n",
      " 'Soure' 'Breves' 'Tucuruí' 'SERRA DOS CARAJAS' 'Itaituba' 'Óbidos'\n",
      " 'Santana do Araguaia' 'Tucumã' 'Novo Repartimento' 'Cametá'\n",
      " 'Monte Alegre' 'Marabá' 'Conceição do Araguaia' 'MINA DO PALITO'\n",
      " 'Xinguara' 'Capitão Poço' 'Santarém' 'Dom Eliseu' 'Altamira' 'Redenção']\n"
     ]
    }
   ],
   "source": [
    "# do link: https://stackoverflow.com/a/31607735\n",
    "def strip_accents(text):\n",
    "    \"\"\"\n",
    "    Strip accents from input String.\n",
    "\n",
    "    :param text: The input string.\n",
    "    :type text: String.\n",
    "\n",
    "    :returns: The processed String.\n",
    "    :rtype: String.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except (TypeError, NameError): # unicode is a default on python 3 \n",
    "        pass\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = text.encode('ascii', 'ignore')\n",
    "    text = text.decode(\"utf-8\")\n",
    "    return str(text)\n",
    "\n",
    "def text_to_id(text):\n",
    "    \"\"\"\n",
    "    Convert input text to id.\n",
    "\n",
    "    :param text: The input string.\n",
    "    :type text: String.\n",
    "\n",
    "    :returns: The processed String.\n",
    "    :rtype: String.\n",
    "    \"\"\"\n",
    "    text = strip_accents(text)\n",
    "    text = re.sub('[ ]+', '_', text)\n",
    "#     text = re.sub('[^0-9a-zA-Z_-]', '', text)\n",
    "    return text\n",
    "\n",
    "df = pd.read_csv(StringIO(dados))\n",
    "df_meta = pd.read_csv(StringIO(metadados))\n",
    "\n",
    "print(df_meta.columns)\n",
    "\n",
    "with open(\"../datasets/para_geo.json\",\"r\",encoding=\"utf-8\") as f:\n",
    "    geo = json.load(f)\n",
    "    cidades = [g[\"properties\"][\"name\"] for g in geo[\"features\"]]\n",
    "    print(cidades)\n",
    "    for cidade in cidades:\n",
    "        indexes_cidade = df[\"Cidade\"] == text_to_id(cidade.upper()).replace(\"_\", \" \")\n",
    "        indexes_df_meta = df_meta[\"ESTAÇÃO\"] == text_to_id(cidade.upper()).replace(\"_\", \" \")\n",
    "        if np.sum(indexes_cidade) > 0:\n",
    "            df[\"Cidade\"][indexes_cidade] = cidade\n",
    "            df_meta[\"ESTAÇÃO\"][indexes_df_meta] = cidade\n",
    "    print(df[\"Cidade\"].unique())\n",
    "    print(df_meta[\"ESTAÇÃO\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dá pra ver que no meio das cidades tem uma serra e uma mina, que não tem uma cidade referenciada mas tem sensores. Pra fins didáticos, vamos ignorar isso nas aulas. Só precisamos fazer uma troca manual, a cidade de Tomé-Açu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-d9d7fb24a15e>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Cidade\"][df[\"Cidade\"] == \"TOME ACU\"] = 'Tomé-Açu'\n",
      "<ipython-input-11-d9d7fb24a15e>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta[\"ESTAÇÃO\"][df_meta[\"ESTAÇÃO\"] == \"TOME ACU\"] = 'Tomé-Açu'\n"
     ]
    }
   ],
   "source": [
    "df[\"Cidade\"][df[\"Cidade\"] == \"TOME ACU\"] = 'Tomé-Açu'\n",
    "df_meta[\"ESTAÇÃO\"][df_meta[\"ESTAÇÃO\"] == \"TOME ACU\"] = 'Tomé-Açu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Belém', 'Castanhal', 'Medicilândia', 'Pacajá', 'Placas',\n",
       "       'Paragominas', 'Tomé-Açu', 'Rondon do Pará', 'Salinópolis',\n",
       "       'São Félix do Xingu', 'Bragança', 'Soure', 'Breves', 'Tucuruí',\n",
       "       'SERRA DOS CARAJAS', 'Itaituba', 'Óbidos', 'Santana do Araguaia',\n",
       "       'Tucumã', 'Novo Repartimento', 'Cametá', 'Monte Alegre', 'Marabá',\n",
       "       'Conceição do Araguaia', 'MINA DO PALITO', 'Xinguara',\n",
       "       'Capitão Poço', 'Santarém', 'Dom Eliseu', 'Altamira', 'Redenção'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Cidade\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGIÃO</th>\n",
       "      <th>UF</th>\n",
       "      <th>ESTAÇÃO</th>\n",
       "      <th>CODIGO (WMO)</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ALTITUDE</th>\n",
       "      <th>DATA DE FUNDAÇÃO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>PA</td>\n",
       "      <td>Belém</td>\n",
       "      <td>A201</td>\n",
       "      <td>-1.411228</td>\n",
       "      <td>-48.439512</td>\n",
       "      <td>21.17</td>\n",
       "      <td>20/01/03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>PA</td>\n",
       "      <td>Castanhal</td>\n",
       "      <td>A202</td>\n",
       "      <td>-1.300875</td>\n",
       "      <td>-47.947967</td>\n",
       "      <td>47.13</td>\n",
       "      <td>24/01/03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "      <td>PA</td>\n",
       "      <td>Medicilândia</td>\n",
       "      <td>A209</td>\n",
       "      <td>-3.510943</td>\n",
       "      <td>-52.963450</td>\n",
       "      <td>251.68</td>\n",
       "      <td>17/02/08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>PA</td>\n",
       "      <td>Pacajá</td>\n",
       "      <td>A210</td>\n",
       "      <td>-3.843611</td>\n",
       "      <td>-50.638056</td>\n",
       "      <td>89.02</td>\n",
       "      <td>27/02/08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>PA</td>\n",
       "      <td>Placas</td>\n",
       "      <td>A211</td>\n",
       "      <td>-3.864040</td>\n",
       "      <td>-54.216416</td>\n",
       "      <td>100.45</td>\n",
       "      <td>14/02/08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  REGIÃO  UF       ESTAÇÃO CODIGO (WMO)  LATITUDE  LONGITUDE  ALTITUDE  \\\n",
       "0      N  PA         Belém         A201 -1.411228 -48.439512     21.17   \n",
       "1      N  PA     Castanhal         A202 -1.300875 -47.947967     47.13   \n",
       "2      N  PA  Medicilândia         A209 -3.510943 -52.963450    251.68   \n",
       "3      N  PA        Pacajá         A210 -3.843611 -50.638056     89.02   \n",
       "4      N  PA        Placas         A211 -3.864040 -54.216416    100.45   \n",
       "\n",
       "  DATA DE FUNDAÇÃO  \n",
       "0         20/01/03  \n",
       "1         24/01/03  \n",
       "2         17/02/08  \n",
       "3         27/02/08  \n",
       "4         14/02/08  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos o processo para os metadados, e vamos salvar tudo em disco. Vamos fazer uma transformação e juntar data e hora na mesma coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntando as colunas de data e hora\n",
    "df[\"Data\"] = pd.to_datetime(df['Data'] + ' ' + df['Hora'])\n",
    "df = df.drop([\"Hora\"], axis=1)\n",
    "\n",
    "# Salvando os dados e metadados\n",
    "df.to_csv(\"../datasets/completo.csv\", index=False)\n",
    "df_meta.to_csv(\"../datasets/metadados.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim vamos agrupar pela média de medições pelo dia para criar um arquivo mais leve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leve = df.groupby([\"Cidade\",pd.Grouper(key='Data', freq='W')]).mean()\n",
    "df_leve.reset_index(level=df_leve.index.names, inplace=True)\n",
    "\n",
    "df_leve = df_leve[df_leve[\"Cidade\"].isin(df_leve[\"Cidade\"].unique()[:20:2])]\n",
    "df_leve[\"Cidade\"].unique()\n",
    "df_leve.to_csv(\"../datasets/dados.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deixamos tudo pronto para outra seção."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
